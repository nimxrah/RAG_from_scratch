# -*- coding: utf-8 -*-
"""RAG_from_scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fj-vzw21br1GM4nDgrnEmy1-gkfacqZ0
"""

!pip install chromadb sentence-transformers transformers accelerate

!mkdir -p data

with open("data/company_policy.txt", "w") as f:
    f.write("""
Our refund policy allows customers to request a refund within 30 days of purchase.
Refunds are processed within 5â€“7 business days.
Subscriptions can be canceled anytime, but refunds are only available within 7 days.
""")

from pathlib import Path

def load_documents(folder="data"):
    texts = []
    for file in Path(folder).glob("*.txt"):
        texts.append(file.read_text())
    return texts

def chunk_text(text, chunk_size=300, overlap=50):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start = end - overlap
    return chunks

from sentence_transformers import SentenceTransformer

embedder = SentenceTransformer("all-MiniLM-L6-v2")

def embed_texts(texts):
    return embedder.encode(texts).tolist()

import chromadb

chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection(name="knowledge_base")

def index_documents():
    docs = load_documents()
    chunks = []

    for doc in docs:
        chunks.extend(chunk_text(doc))

    embeddings = embed_texts(chunks)

    collection.add(
        documents=chunks,
        embeddings=embeddings,
        ids=[f"chunk_{i}" for i in range(len(chunks))]
    )

    print(f"Indexed {len(chunks)} chunks")

index_documents()

def retrieve_chunks(query, k=3):
    query_embedding = embed_texts([query])[0]

    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k
    )

    return results["documents"][0]

from transformers import pipeline

generator = pipeline(
    "text2text-generation",
    model="google/flan-t5-small",
    max_length=256
)

def build_prompt(context_chunks, question):
    context = "\n\n".join(context_chunks)

    return f"""
Answer the question using ONLY the context below.
If the answer is not present, say "I don't know".

Context:
{context}

Question:
{question}
"""

def generate_answer(prompt):
    output = generator(prompt)
    return output[0]["generated_text"]

def rag_query(question):
    chunks = retrieve_chunks(question)
    prompt = build_prompt(chunks, question)
    return generate_answer(prompt)

print(rag_query("What is the refund policy?"))

print(rag_query("how long are refunds available?"))