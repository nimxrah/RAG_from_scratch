# RAG_from_scratch

An end-to-end **Retrieval-Augmented Generation (RAG)** system built from scratch using open-source tools.  
This project enables a language model to answer questions **only using provided documents**, significantly reducing hallucinations.

---

## ğŸš€ What This Project Does

- Ingests raw text documents
- Splits them into overlapping chunks
- Converts chunks into semantic embeddings
- Stores embeddings in a vector database
- Retrieves the most relevant chunks for a query
- Augments the LLM prompt with retrieved context
- Generates grounded answers using a transformer-based model

---

## ğŸ§  Why RAG?

Traditional language models rely solely on training data and may hallucinate or provide outdated information.  
RAG solves this by **retrieving real documents at query time** and forcing the model to answer based on them.

---

## ğŸ—ï¸ Architecture Overview

User Question  
â†’ Embedding  
â†’ Vector Search (ChromaDB)  
â†’ Relevant Document Chunks  
â†’ Prompt Augmentation  
â†’ Language Model  
â†’ Grounded Answer

---

## ğŸ§© Tech Stack (100% Free)

| Component | Tool |
|--------|------|
| Embeddings | SentenceTransformers (all-MiniLM-L6-v2) |
| Vector Database | ChromaDB |
| Language Model | google/flan-t5-small |
| Platform | Google Colab |
| Language | Python |

---

## ğŸ“‚ Project Structure


